{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAP6618 Spring 2018\n",
    "Assignment 3\n",
    "Christian Garbin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses scikit-learn's ```KNeighborsClassifier``` to classify digits from the MNIST dataset. ```KNeighborsClassifier``` was chosen based on the experiments detailed in the accompanying report.\n",
    "\n",
    "The code in this notebook is mostly adapted from the assignment notebook, which in turn was based on the code in A. GÃ©ron's \"Hands-On Machine Learning with Scikit-Learn and TensorFlow\".\n",
    "\n",
    "**This notebook assumes Python 3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is organized in these sections, in the order they appear:\n",
    "\n",
    "1. Setup of global imports and parameters\n",
    "2. Load and inspect the dataset\n",
    "3. Training and evaluation of the selected classifier, with the final hyperparameters\n",
    "4. Tuning of the selected classifier to choose hyperparameters\n",
    "\n",
    "Logically section 4 has to be done before section 3. However, showing training and evaluation of the final classifier first resulted in a better (IMO) flow of the notebook. It makes the pipeline more visible, without adding the distraction of tuning. Once the pipeline is visible, we can layer on top of it the \"branches\", such as the tuning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries and Jupyter global configuration options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the notebook reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and split the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "    mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings\n",
    "    sort_by_target(mnist) # fetch_openml() returns an unsorted dataset\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is already split into train and test set. The first 60,000 samples are the train set, the last 10,000 are the test set. It has to be split this way because of how the dataset was created. Do **not** shuffle it first. Refer to [LeCun's page](http://yann.lecun.com/exdb/mnist/) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the train set because some classifiers work better with shuffled data. It's mostly needed for classifiers that can get stuck in a local minimum ([reference](https://stats.stackexchange.com/a/311318)), which is not the case with the current classifier. Added here in case this notebook is updated to use another classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the dataset\n",
    "\n",
    "A visualization of the MNIST dataset,\n",
    "\n",
    "TBD........\n",
    "\n",
    "1. Are all classes equally represented? Histogram.\n",
    "1. Visualize some digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic check to perform in a data set is class imbalance.\n",
    "\n",
    "The histograms below plots the number of occurrences of each digit in the train and test set.\n",
    "\n",
    "We can see that the data set is generally well balanced. Some digits are more represented than others, but not by a large margin. We can also see than the train and test set are balanced between them, with similar digit frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.hist(y_train)\n",
    "plt.ylabel('Train set - number of digits in each class')\n",
    "plt.subplot(122)\n",
    "plt.hist(y_test)\n",
    "plt.ylabel('Test set - number of digits in each class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluating\n",
    "\n",
    "In this section the classifier is trained and evluated. The following sections tune the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `KneighborsClassifier` based on its combination of train time, test time and accuracy.\n",
    "\n",
    "Note that to achieve a manageable test time we are using `n_jobs=-1`, to parallelize the work as much as possible.\n",
    "\n",
    "Also note that the time spent in `.fit(...)` for this classifier is deceiving. This classifier does not have a proper training phase. All the work is done at test time (e.g. in `cross_val_score`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "CPU times: user 17.7 s, sys: 84.4 ms, total: 17.7 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "\n",
    "fit_results = clf.fit(X_train, y_train)\n",
    "print(fit_results)  # Need to explicitly print results because of %%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform a thorough evaluation with cross-validation. \n",
    "\n",
    "This will take a while to run (about 12 minutes on a MacBook i7 2.9 GHz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go into details of performance with a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict every single instance in the training data\n",
    "y_train_pred = cross_val_predict(clf, X_train, y_train, cv=3, n_jobs=-1)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the confusion matrix as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The picture above gives a general idea of how well each number is classified (lighter colors = higher values = better classification). For example, the digit one is generally classified correctly, while the digit eight has more classification errors.\n",
    "\n",
    "Confirming the visual inspection with some math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Digit one accuracy:   {}\".format(conf_mx[1][1]/sum(conf_mx[1])))\n",
    "print(\"Digit eight accuracy: {}\".format(conf_mx[8][8]/sum(conf_mx[8])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see where the misclassifications happen we will remove the diagonal (correct classifications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each row so one class doesn't dominate the values, skewing the heatmap\n",
    "# This is not strictly necessary in this case because MNIST classes are well-balanced\n",
    "# It's good practice nevertheless\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "conf_mx_misclassifications = conf_mx / row_sums\n",
    "\n",
    "# Remove correct classifications (leaves only misclassifications in the matrix)\n",
    "np.fill_diagonal(conf_mx_misclassifications, 0)  \n",
    "\n",
    "plt.matshow(conf_mx_misclassifications, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this matrix lighter colors = higher values = higher misclassification ratios.\n",
    "\n",
    "The brighest spot happens in the intersection of digit 4 (row) and digit 9 (column). That means the classifier is classifying a (relatively) large number of 4s as 9s.\n",
    "\n",
    "There is also a bright (although not as bright) spot in the intersection of digit 9 (row) and digit 4 (column), indicating that some 9s are misclassified as 4s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show examples of 4s and 9s that are correctly and incorrectly classified.\n",
    "\n",
    "First, find the samples that are correctly and incorrecly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_a, cl_b = 4, 9\n",
    "\n",
    "# All cl_a digits that are correctly classified (predicted)\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "\n",
    "# All cl_a digits that are mistakenly classified as cl_b\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "\n",
    "# All cl_b digits mistakenly classified as cl_a\n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "\n",
    "# All cl_b digits that are correctly classified\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot them. The plot below will show a sample of 4s and 9s as:\n",
    "\n",
    "|Classifed as 4|Classified as 9|\n",
    "|----|----|\n",
    "| 4s correctly classified as 4s | 4s incorrecly classified as 9s |\n",
    "| 9s incorrectly classified as 4s | 9s correctly classified as 9s |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
    "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)  # Need to explicitly print because of %%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers two aspects of tuning:\n",
    "\n",
    "- Feature manipulation, more specifially, feature normalization (scaling).\n",
    "- Hyperameters, i.e. parameters that affect the behavior of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature normalization (scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before trying any tuning, we need to check if normalizing the features has any effect in the classifier.\n",
    "\n",
    "The calculations used by some classifiers can be affected by large differences in feature values.\n",
    "\n",
    "KNN uses the feature values to calculate distances between samples. Because there is a large variance of values between pixels in an MNIST sample (from 0 to 255), we will check if normalizing the samples affect the KNN algorithm by scaling the images.\n",
    "\n",
    "The tests below show that accuracy decreases when features are scaled (somewhat surprinsigly - to be investigated later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "\n",
    "scores = cross_val_score(clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two important parameters for a KNN classifier are\n",
    "\n",
    "- Number of neighbors to include in the distance (similarity) calculations - the `n_neighbors` parameter\n",
    "- How the distance between two samples is calculated - `metric` parameter\n",
    "\n",
    "In this section we will try different values for these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tests below show that\n",
    "\n",
    "* Decreasing the number of neighbors does not affect the accuracy by much.\n",
    "* Increasing the number of neighbors lowers the accuracy.\n",
    "* In both cases the test time is about the same. This is somewhat surprising, since adding more neighbors would increase the time to calculate the distance. However, in this case the number of features (784 pixels per image) and the large number of samples likely dominate the run time (dimensionality reduction would make a difference here).\n",
    "\n",
    "Therefore we will keep using a relative small, but not too small, number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=30, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance algorithm (metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this hyperparameter tuning we attempted to use \"Manhattan\" as the distance (the default value, used above, is Euclidean distance). This measure was used because [this article](https://arxiv.org/pdf/1708.04321.pdf) shows in table 1 that the Manhattan distance often performs well (although the tests are not necessarily in the same domain, of image classification).\n",
    "\n",
    "The test below show that average accuracy decreases by a small margin and the test time remains about the same.\n",
    "\n",
    "Therefore we will keep using Euclidean distance (the default value) for the distance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3, n_jobs=-1, metric=\"manhattan\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
