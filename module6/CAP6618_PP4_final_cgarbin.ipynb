{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAP 6618 - Machine Learning for Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christian Garbin\n",
    "Spring 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Project 4\n",
    "See guidelines on Canvas for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is structured as follows:\n",
    "\n",
    "1. Section 1 has the basic setup for the notebok, e.g. libraries used in several cells\n",
    "1. Section 2 has functions to load and prepare the dataset\n",
    "1. Section 3 rebuilds the network selected in the _experiments_ notebook, to have a clean baseline\n",
    "1. Section 4 attempts another approach at transfer learning to improve the results from section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To protect against running on FAU's HPC (as of April 2019). We need at least Keras 2.2, where VGG networks support the native CIFAR-10 shape of (32, 32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "if keras.__version__.startswith('2.1'):\n",
    "    print('ERROR: This notebook requires at least Keras 2.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def load_dataset():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('Loaded {} train and {} test samples'.format(x_train.shape[0], x_test.shape[0]))\n",
    "\n",
    "    # Keras' CIFAR-10 is stored as integer\n",
    "    # Later pieces of code need the data in float type\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    # Since we are using a neural network, we need to convert the categories from labels\n",
    "    # (numbers) to a hot-encoded vector\n",
    "    # See https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\n",
    "    # on why we need to hot-encode in this case\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    print('Hot-enconding {} classes'.format(num_classes))\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "    \n",
    "    # Most examples using CIFAR-10 have the lines of code below as part of loading and\n",
    "    # preparing the dataset. Since we are using a pretrained network, we will use the\n",
    "    # network's `preprocess_input()` instead. It will take care of it and anything\n",
    "    # else that was done to the image at training time for that network.\n",
    "    # x_train /= 255\n",
    "    # x_test /= 255\n",
    "          \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Network from the _experiments_ notebook (bottleneck transfer learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the _experiments_ notebook we used [bottleneck transfer learning](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html). \n",
    "\n",
    "In this transfer learning method, we extract features from the convolution layers and use them to train another network (usually composed of dense layers).\n",
    "\n",
    "This section reproduces the bottleneck transfer from the _experiments_ notebook to create a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load the base network, without the dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base network is Keras' pretrained VGG16.\n",
    "\n",
    "Contrary to what we did in the _experiments_ notebook, we specify an `input_shape` that matches the CIFAR-10 images. This is needed for the section where we train the base model together with a new top layer. To \"glue\" them together we need exact dimensions for the last layer of the base model (to serve as `input_shape` for the new top layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "\n",
    "conv_base = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "Loaded 50000 train and 10000 test samples\n",
      "Hot-enconding 10 classes\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features from the training set.\n",
    "\n",
    "Since this is the most time consuming step of the bottleneck transfer learning process, we will save the results to a file and attempt to restore from that file before calculating the predictions agian. \n",
    "\n",
    "**IMPORTANT:** if anything changes in the prediction process (e.g. a different base network configuration), remember to delete the files to force new predictions to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "\n",
    "\"\"\" Preprocess and store results of `predict()` for an array of images.\"\"\" \n",
    "def predict_all_images(images, model, base_module, new_size=None):\n",
    "    print('Predicting {} images'.format(len(images)))\n",
    "\n",
    "    predictions = []\n",
    "    for i, img in enumerate(images):\n",
    "        # Simple progress indicator\n",
    "        if i % 500 == 0:\n",
    "            print('{}'.format(i), end=\", \")\n",
    "            \n",
    "        # Resize, if asked to do so\n",
    "        if new_size is not None:\n",
    "            img = transform.resize(img, new_size, order=1, mode='reflect')\n",
    "            \n",
    "        # Expand dimensions to match the format Keras needs in `predict()`\n",
    "        # In gist: add one more dimension to hold the batch size (1 image in this case)\n",
    "        x = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Normalize pixel values to what the model was trained one\n",
    "        # It varies by model - see https://stackoverflow.com/a/47556342\n",
    "        x = base_module.preprocess_input(x)\n",
    "\n",
    "        predictions.append(model.predict(x))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "\"\"\" Load cached predictions, if avaiable. If not, predict and cache them.\"\"\"\n",
    "def calculate_predictions(dataset, model, file_name):\n",
    "    if os.path.isfile(file_name):\n",
    "        print('Loading predictions from {}'.format(file_name))\n",
    "        with open (file_name, 'rb') as fp:\n",
    "            features = pickle.load(fp)\n",
    "    else:\n",
    "        features = predict_all_images(dataset, model, vgg16, new_size=None)\n",
    "        with open(file_name, 'wb') as fp:\n",
    "            pickle.dump(features, fp)\n",
    "            \n",
    "    # At this point we may have a list (from predict_all_images)\n",
    "    # Change to a NumPy array - what the network expects\n",
    "    features = np.asarray(features)\n",
    "    \n",
    "    # We also have one extra layer in the array, (<samples>, 1, 1, 1, x), while\n",
    "    # the networks expect four dimensions,  (<samples>, 1, 1, x)\n",
    "    features = np.squeeze(features, axis=1)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 50000 images\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, 23500, 24000, 24500, 25000, 25500, 26000, 26500, 27000, 27500, 28000, 28500, 29000, 29500, 30000, 30500, 31000, 31500, 32000, 32500, 33000, 33500, 34000, 34500, 35000, 35500, 36000, 36500, 37000, 37500, 38000, 38500, 39000, 39500, 40000, 40500, 41000, 41500, 42000, 42500, 43000, 43500, 44000, 44500, 45000, 45500, 46000, 46500, 47000, 47500, 48000, 48500, 49000, 49500, CPU times: user 45min 19s, sys: 3min 27s, total: 48min 46s\n",
      "Wall time: 9min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TRAIN_FEATURES_FILE = 'predicted_train_features_final_notebook'\n",
    "x_train_features = calculate_predictions(x_train, conv_base, TRAIN_FEATURES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10000 images\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, CPU times: user 9min 13s, sys: 43.3 s, total: 9min 56s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TEST_FEATURES_FILE = 'predicted_test_features_final_notebook'\n",
    "x_test_features = calculate_predictions(x_test, conv_base, TEST_FEATURES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Train the final classifier on the extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the classifier.\n",
    "\n",
    "A few observations from experiments:\n",
    "\n",
    "- Batch normalization resulted in better accuracy than dropout\n",
    "- Learning rate can be reasonably high, thanks to batch normalization, resulting in convergence after a few epochs\n",
    "- Small dense layers performed nearly as well as large dense layers (> 1024) and are faster to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers \n",
    "from keras import losses\n",
    "\n",
    "model = models.Sequential()\n",
    "# Since we extracted predictions from a convolution layer, the first step is to\n",
    "# flatten the results, just we like we do when we train the complete network.\n",
    "# TODO: make more generic with x_train_features.shape[1:]\n",
    "model.add(layers.Flatten(input_shape=(1, 1, 512,)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier, using early stopping to get a good accuracy without much guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 3s 71us/step - loss: 1.1770 - acc: 0.5940 - val_loss: 0.9947 - val_acc: 0.6698\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 3s 57us/step - loss: 0.9979 - acc: 0.6501 - val_loss: 0.9668 - val_acc: 0.6724\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.9491 - acc: 0.6666 - val_loss: 0.9483 - val_acc: 0.6868\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 3s 65us/step - loss: 0.9181 - acc: 0.6793 - val_loss: 0.9449 - val_acc: 0.6888\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 3s 67us/step - loss: 0.8866 - acc: 0.6910 - val_loss: 0.9513 - val_acc: 0.6820\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 3s 59us/step - loss: 0.8721 - acc: 0.6944 - val_loss: 0.9473 - val_acc: 0.6866\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_acc', patience=2, verbose=1)\n",
    "\n",
    "history = model.fit(x_train_features, y_train,\n",
    "                    epochs=100, \n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Evaluate the final classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://keras.io/visualization/ - changed to side-by-side plots to save space\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_keras_history(history):\n",
    "\n",
    "    # Side-by-side plots, wider than taller, to make run for the epochs\n",
    "    f = plt.figure(figsize=(12,4))\n",
    "    ax_acc = f.add_subplot(121)\n",
    "    ax_loss = f.add_subplot(122)\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    ax_acc.plot(history.history['acc'])\n",
    "    ax_acc.plot(history.history['val_acc'])\n",
    "    ax_acc.set_title('Model accuracy')\n",
    "    ax_acc.set_ylabel('Accuracy')\n",
    "    ax_acc.set_xlabel('Epoch')\n",
    "    ax_acc.legend(['Train', 'Test'], loc='upper left')\n",
    "    ax_acc.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    ax_loss.plot(history.history['loss'])\n",
    "    ax_loss.plot(history.history['val_loss'])\n",
    "    ax_loss.set_title('Model loss')\n",
    "    ax_loss.set_ylabel('Loss')\n",
    "    ax_loss.set_xlabel('Epoch')\n",
    "    ax_loss.legend(['Train', 'Test'], loc='upper left')\n",
    "    ax_loss.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_keras_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 19us/step\n",
      "Test loss: 0.9718010419845581\n",
      "Test accuracy: 0.6737\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test_features, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transfer learning with retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will load the same pretrained network used in the previous section and train some of its top layers on our dataset.\n",
    "\n",
    "Even though these top layers are supposed to be generic feature extractors, they were trained on a different set of images. \n",
    "\n",
    "The goal of retraining the top layers is for them to learn features from our dataset.\n",
    "\n",
    "Note: we could have proceeded from the previous section, where we already have a base network and a pretrained dense layer (two pieces we need for this section). However, in this section we will rebuild those steps to 1) have a complete solution in one place and 2) make sure we are not carrying over information from that section that could inadvertently help in this section (e.g. train again a network that has already been trained)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load and prepare the base network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will retrain the last series of convolution layers (and their associated pooling layer) in the VGG network.\n",
    "\n",
    "In this step we load the base network and freeze all layers we will not train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\t(None, 32, 32, 3)\tFalse\t\n",
      "block1_conv1\t(None, 32, 32, 64)\tFalse\t\n",
      "block1_conv2\t(None, 32, 32, 64)\tFalse\t\n",
      "block1_pool\t(None, 16, 16, 64)\tFalse\t\n",
      "block2_conv1\t(None, 16, 16, 128)\tFalse\t\n",
      "block2_conv2\t(None, 16, 16, 128)\tFalse\t\n",
      "block2_pool\t(None, 8, 8, 128)\tFalse\t\n",
      "block3_conv1\t(None, 8, 8, 256)\tFalse\t\n",
      "block3_conv2\t(None, 8, 8, 256)\tFalse\t\n",
      "block3_conv3\t(None, 8, 8, 256)\tFalse\t\n",
      "block3_pool\t(None, 4, 4, 256)\tFalse\t\n",
      "block4_conv1\t(None, 4, 4, 512)\tFalse\t\n",
      "block4_conv2\t(None, 4, 4, 512)\tFalse\t\n",
      "block4_conv3\t(None, 4, 4, 512)\tFalse\t\n",
      "block4_pool\t(None, 2, 2, 512)\tFalse\t\n",
      "block5_conv1\t(None, 2, 2, 512)\tTrue\t\n",
      "block5_conv2\t(None, 2, 2, 512)\tTrue\t\n",
      "block5_conv3\t(None, 2, 2, 512)\tTrue\t\n",
      "block5_pool\t(None, 1, 1, 512)\tTrue\t\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "\n",
    "conv_base2 = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze all layers we don't want to train\n",
    "for layer in conv_base2.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check if we got what we wanted\n",
    "for layer in conv_base2.layers:\n",
    "    print('{}\\t{}\\t{}\\t'.format(layer.name, layer.output_shape, layer.trainable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create and prepare the top layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top layer of the network will do the final class predictions. To do that, it will be trained on our dataset, together with the layers from the base network we unfroze in the previous step.\n",
    "\n",
    "However, before training the top layer and the base network together, we first need to train the top layer by itself. The reason for that is explained in [this Keras blog post on transfer learning](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html):\n",
    "\n",
    "> in order to perform fine-tuning, all layers should start with properly trained weights: for\n",
    "> instance you should not slap a randomly initialized fully-connected network on top of a\n",
    "> pre-trained convolutional base. This is because the large gradient updates triggered by the\n",
    "> randomly initialized weights would wreck the learned weights in the convolutional base. In \n",
    "> our case this is why we first train the top-level classifier, and only then start fine-tuning\n",
    "> convolutional weights alongside it.\n",
    "\n",
    "In this step we will create weights for the top layer that are compatible with the convolution layer of the base network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we use the top layer in a few places, this function ensures that we always create the top layer with the same architecture in all places.\n",
    "\n",
    "**IMPORTANT:** If you change this function, run all steps that depend on it again, including the weight generation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_layer(input_shape):\n",
    "    top_layer = models.Sequential()\n",
    "    top_layer.add(layers.Flatten(input_shape=input_shape))\n",
    "    top_layer.add(layers.Dense(128, activation='relu'))\n",
    "    top_layer.add(layers.BatchNormalization())\n",
    "    top_layer.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    return top_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starting point is the features extracted in the previous section. They were generated by the base layer and are therefore adjusted to the weights those layers uses.\n",
    "\n",
    "The extracted features are now the training data for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "Loaded 50000 train and 10000 test samples\n",
      "Hot-enconding 10 classes\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from predicted_train_features_final_notebook\n",
      "Loading predictions from predicted_test_features_final_notebook\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: since the base model we use in this section is exactly the same as the one\n",
    "# used in the previous section, we can use the same cached files. If the models become\n",
    "# different in the future, we need new file names in this section.\n",
    "\n",
    "x_train_features = calculate_predictions(x_train, conv_base2, TRAIN_FEATURES_FILE)\n",
    "x_test_features = calculate_predictions(x_test, conv_base2, TEST_FEATURES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the layer and save the weights. These weights are the \"properly trained weights\" that we need.\n",
    "\n",
    "This step will take only a few seconds because we are training a very small network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses\n",
    "\n",
    "top_layer_weights = get_top_layer(x_train_features.shape[1:])\n",
    "\n",
    "top_layer_weights.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "                  loss=losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 1.1473 - acc: 0.6053 - val_loss: 0.9806 - val_acc: 0.6636\n",
      "Epoch 2/50\n",
      "45000/45000 [==============================] - 4s 81us/step - loss: 0.9910 - acc: 0.6602 - val_loss: 0.9525 - val_acc: 0.6646\n",
      "Epoch 3/50\n",
      "45000/45000 [==============================] - 4s 80us/step - loss: 0.9426 - acc: 0.6759 - val_loss: 0.9299 - val_acc: 0.6766\n",
      "Epoch 4/50\n",
      "45000/45000 [==============================] - 4s 80us/step - loss: 0.9096 - acc: 0.6872 - val_loss: 0.9175 - val_acc: 0.6918\n",
      "Epoch 5/50\n",
      "45000/45000 [==============================] - 4s 80us/step - loss: 0.8789 - acc: 0.6958 - val_loss: 0.9209 - val_acc: 0.6848\n",
      "Epoch 6/50\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.8513 - acc: 0.7097 - val_loss: 0.9203 - val_acc: 0.6860\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a07e320>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "# We will train with early stopping to get good results, but also not waste\n",
    "# time with too much training (and risk overfitting as well)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_acc', patience=2, verbose=1)\n",
    "\n",
    "top_layer_weights.fit(x_train_features, y_train,\n",
    "                      epochs=50,\n",
    "                      batch_size=20,\n",
    "                      validation_split=0.1,\n",
    "                      callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 16us/step\n",
      "Test loss: 0.9462532428741455\n",
      "Test accuracy: 0.6826\n"
     ]
    }
   ],
   "source": [
    "scores = top_layer_weights.evaluate(x_test_features, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_FILE = 'bottleneck_layer_weights.h5'\n",
    "\n",
    "top_layer_weights.save_weights('bottleneck_layer_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We no longer need this model - free up some memory\n",
    "del top_layer_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Train with the base network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section we already achieved over 90% accuracy.\n",
    "\n",
    "In this section we will train the base network together with the new top layers to improve that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** when running the notebook from top to bottom, we could simply use the top layer we just trained in the above section. We are doing it in separate steps (train, save to file, load from file) to illustrate the full workflow and to be able to run only this section of the notebook later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layer = get_top_layer(conv_base2.output_shape[1:])\n",
    "top_layer.load_weights(WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = models.Sequential()\n",
    "combined_model.add(conv_base2)\n",
    "combined_model.add(top_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the model we built.\n",
    "\n",
    "What we are looking for here: a large number of non-trainable parameters. If that numbers is small, we didn't freeze the layers correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 10)                67466     \n",
      "=================================================================\n",
      "Total params: 14,782,154\n",
      "Trainable params: 7,146,634\n",
      "Non-trainable params: 7,635,520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model.\n",
    "\n",
    "Note that we are using a large learning rate. We can afford that because we are using batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "                  loss=losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "45000/45000 [==============================] - 805s 18ms/step - loss: 1.1864 - acc: 0.5726 - val_loss: 1.8449 - val_acc: 0.4940\n",
      "Epoch 2/50\n",
      "45000/45000 [==============================] - 804s 18ms/step - loss: 0.9409 - acc: 0.6720 - val_loss: 1.1389 - val_acc: 0.6074\n",
      "Epoch 3/50\n",
      "45000/45000 [==============================] - 824s 18ms/step - loss: 0.8637 - acc: 0.7030 - val_loss: 1.0129 - val_acc: 0.6500\n",
      "Epoch 4/50\n",
      "45000/45000 [==============================] - 768s 17ms/step - loss: 0.8070 - acc: 0.7237 - val_loss: 0.9557 - val_acc: 0.6920\n",
      "Epoch 5/50\n",
      "45000/45000 [==============================] - 865s 19ms/step - loss: 0.7621 - acc: 0.7401 - val_loss: 0.9144 - val_acc: 0.6996\n",
      "Epoch 6/50\n",
      "45000/45000 [==============================] - 845s 19ms/step - loss: 0.7221 - acc: 0.7520 - val_loss: 0.8891 - val_acc: 0.6948\n",
      "Epoch 7/50\n",
      "45000/45000 [==============================] - 836s 19ms/step - loss: 0.6864 - acc: 0.7655 - val_loss: 0.8678 - val_acc: 0.7124\n",
      "Epoch 8/50\n",
      "45000/45000 [==============================] - 791s 18ms/step - loss: 0.6599 - acc: 0.7733 - val_loss: 1.0339 - val_acc: 0.6662\n",
      "Epoch 9/50\n",
      "45000/45000 [==============================] - 797s 18ms/step - loss: 0.6321 - acc: 0.7842 - val_loss: 0.9180 - val_acc: 0.7034\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14c274f98>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit(x_train, y_train,\n",
    "                   epochs=50,\n",
    "                   batch_size=20,\n",
    "                   validation_split=0.1,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 52s 5ms/step\n",
      "Test loss: 0.9208349465370178\n",
      "Test accuracy: 0.7047\n"
     ]
    }
   ],
   "source": [
    "scores = combined_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and visualize the confusion matrix.\n",
    "\n",
    "(Reminder: rows = actual class, columns = predicted class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 48s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = combined_model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[838  65  22   3  29   1   4  20   6  12]\n",
      " [  2 956   2   0   1   1   6   5   1  26]\n",
      " [ 48  20 640   3 117  47  81  42   0   2]\n",
      " [ 16  31  72 199  85 359 128  71   1  38]\n",
      " [ 12  10  34   1 740  21  76 100   2   4]\n",
      " [  9  12  32  15  49 682  74 119   0   8]\n",
      " [  4  28  28   3  32  20 877   4   0   4]\n",
      " [  6  13  12   0  47  30   7 873   0  12]\n",
      " [134 229  13   8  19   1   3   5 538  50]\n",
      " [ 20 237   2   1   8   3   5  19   1 704]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In graphical format (lighter colors = higher accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(cm, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis and conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with an unfrozen convolution layer improves overall accuracy by about 2%.\n",
    "\n",
    "Although the numbers in the notebook show that the cost for that improvement is a much large training time (from \"a few seconds\" to \"about two hours\"), on a GPU the training time would be significantly faster, in the range of \"a few minutes\". It is still larger, but back to a more manageable range.\n",
    "\n",
    "Applications that require maximum accuracy should unfreeze a convolution layer. Applications that require the minimum possible training time (perhaps online training, as samples are collected) should freeze all convolution layers and train only the smallest possible dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Possible next steps to improve the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process is already stopping when overfit begins to happen (using early stopping), so training for longer in this configuration may not yield better results.\n",
    "\n",
    "With that in mind, a few ideas to improve accuracy:\n",
    "\n",
    "1. Increase the `patience` value in early stopping to check if the network is going through a plateau at that point.\n",
    "1. Add data augmentation.\n",
    "1. Change the architecture of the top layer, e.g. add more hidden layers, add/remove neurons, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
